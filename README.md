# Telco Customer Churn Prediction (XGBoost)

Interactive churn prediction for a telco dataset with an end-to-end ML pipeline: preprocessing â†’ model selection â†’ hyperparameter tuning â†’ threshold calibration â†’ deployment (Streamlit) + business dashboard (Power BI).

**Final model**: XGBoost  
**Threshold**: 0.4 (business-driven, maximize recall for retention)  
**Key metrics (test)**: Precision â‰ˆ 0.50 â€¢ Recall â‰ˆ 0.86 â€¢ F1 â‰ˆ 0.63 â€¢ ROC-AUC â‰ˆ 0.84

## ğŸš€ Quickstart (Local)

```bash
# 1) create env (optional)
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# 2) install deps
pip install -r requirements.txt

# 3) run app
streamlit run app/streamlit_app.py

```
Artifacts are already included in artifacts/.
If you retrain, re-export the three files again:

- final_xgb_model.joblib

- final_threshold.npy

- train_columns.json (must match the training feature order)

## ğŸŒ Deploy
**Option A â€” Streamlit Community Cloud** 

1. Push this repo to GitHub (public).

2. Go to share.streamlit.io â†’ â€œNew appâ€ â†’ select your repo.

3. Set Main file path: app/streamlit_app.py.

4. Add requirements.txt.

**Option B â€” Hugging Face Spaces**

1. Create a new Space â†’ Streamlit template.

2. Upload repo (or connect Git).

3. Set app/streamlit_app.py as the entry point.

## ğŸ“Š Model & Business Summary

- Goal: Identify customers likely to churn and prioritize retention offers.

- Model: XGBoost tuned via RandomizedSearchCV + Stratified K-Fold CV.

- Threshold 0.4: chosen to maximize recall (catch more true churners), which aligns with retention use-cases.

**Top drivers (typical on Telco dataset):**

- Contract type (Month-to-month vs. 1â€“2 year)

- Tenure (low tenure â†’ higher risk)

- Monthly charges (higher â†’ higher risk)

- Internet service (Fiber optic group shows higher churn)

- Tech support (No support â†’ higher churn)

Suggested actions:

- Lock-in offers for month-to-month / short-tenure customers

- Improve fiber-optic satisfaction touchpoints

- Incentivize value-add services (e.g., tech support)

## ğŸ§ª Reproducibility

**Open the notebook:**
```
src/TelcoChurnPrediction.ipynb
```
**What it contains:**

- Data cleaning & encoding

- Train/test split (stratified)

- Models compared: Logistic Regression, Random Forest, XGBoost

- Hyperparameter tuning (RandomizedSearchCV)

- Threshold sweep (0.3â€“0.7) and selection (0.4)

- Export artifacts:
    ```py
    import os, json, joblib, numpy as np
    os.makedirs("../artifacts", exist_ok=True)

    joblib.dump(final_xgb, "../artifacts/final_xgb_model.joblib")
    np.save("../artifacts/final_threshold.npy", np.array([0.4]))
    json.dump(X_train.columns.tolist(), open("../artifacts/train_columns.json","w"))
    ```
## ğŸ“Š Power BI Dashboard for Insight

<p align="center">
  <img src="image.png" alt="Power BI Dashboard" width="950">
</p>